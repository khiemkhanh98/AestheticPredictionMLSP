{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WdOjh0EKINim"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "\n",
    "#drive.mount('/content/gdrive')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 49061,
     "status": "ok",
     "timestamp": 1646737966303,
     "user": {
      "displayName": "khiem nguyen trong",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "06117067585511458128"
     },
     "user_tz": -60
    },
    "id": "Zc2IWkZyNqW1",
    "outputId": "558b28e8-ee49-4f42-d865-dd309196c246"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torchinfo\n",
      "  Downloading torchinfo-1.6.3-py3-none-any.whl (20 kB)\n",
      "Installing collected packages: torchinfo\n",
      "Successfully installed torchinfo-1.6.3\n",
      "Collecting torchattacks\n",
      "  Downloading torchattacks-3.2.4-py3-none-any.whl (102 kB)\n",
      "\u001b[K     |████████████████████████████████| 102 kB 4.1 MB/s \n",
      "\u001b[?25hInstalling collected packages: torchattacks\n",
      "Successfully installed torchattacks-3.2.4\n",
      "Requirement already satisfied: pip in /usr/local/lib/python3.7/dist-packages (21.1.3)\n",
      "Collecting install\n",
      "  Downloading install-1.3.5-py3-none-any.whl (3.2 kB)\n",
      "Collecting grad-cam\n",
      "  Downloading grad-cam-1.3.7.tar.gz (4.5 MB)\n",
      "\u001b[K     |████████████████████████████████| 4.5 MB 4.0 MB/s \n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
      "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
      "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
      "Requirement already satisfied: opencv-python in /usr/local/lib/python3.7/dist-packages (from grad-cam) (4.1.2.30)\n",
      "Requirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from grad-cam) (7.1.2)\n",
      "Requirement already satisfied: torch>=1.7.1 in /usr/local/lib/python3.7/dist-packages (from grad-cam) (1.10.0+cu111)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from grad-cam) (1.21.5)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from grad-cam) (4.63.0)\n",
      "Collecting ttach\n",
      "  Downloading ttach-0.0.3-py3-none-any.whl (9.8 kB)\n",
      "Requirement already satisfied: torchvision>=0.8.2 in /usr/local/lib/python3.7/dist-packages (from grad-cam) (0.11.1+cu111)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.7.1->grad-cam) (3.10.0.2)\n",
      "Building wheels for collected packages: grad-cam\n",
      "  Building wheel for grad-cam (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for grad-cam: filename=grad_cam-1.3.7-py3-none-any.whl size=25953 sha256=cc23e34eb550112103e2f8056a9caa7c7ac03b6eef3d5a021ed174dbb5aab790\n",
      "  Stored in directory: /root/.cache/pip/wheels/30/ab/9c/53c523785edffdc6c61755cf82e0dac3342d0d36190c187894\n",
      "Successfully built grad-cam\n",
      "Installing collected packages: ttach, install, grad-cam\n",
      "Successfully installed grad-cam-1.3.7 install-1.3.5 ttach-0.0.3\n",
      "Collecting ray\n",
      "  Downloading ray-1.10.0-cp37-cp37m-manylinux2014_x86_64.whl (59.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 59.6 MB 1.2 MB/s \n",
      "\u001b[?25hRequirement already satisfied: click>=7.0 in /usr/local/lib/python3.7/dist-packages (from ray) (7.1.2)\n",
      "Requirement already satisfied: attrs in /usr/local/lib/python3.7/dist-packages (from ray) (21.4.0)\n",
      "Requirement already satisfied: grpcio>=1.28.1 in /usr/local/lib/python3.7/dist-packages (from ray) (1.44.0)\n",
      "Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from ray) (1.0.3)\n",
      "Requirement already satisfied: jsonschema in /usr/local/lib/python3.7/dist-packages (from ray) (4.3.3)\n",
      "Requirement already satisfied: protobuf>=3.15.3 in /usr/local/lib/python3.7/dist-packages (from ray) (3.17.3)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from ray) (3.6.0)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from ray) (3.13)\n",
      "Requirement already satisfied: numpy>=1.16 in /usr/local/lib/python3.7/dist-packages (from ray) (1.21.5)\n",
      "Collecting redis>=3.5.0\n",
      "  Downloading redis-4.1.4-py3-none-any.whl (175 kB)\n",
      "\u001b[K     |████████████████████████████████| 175 kB 43.5 MB/s \n",
      "\u001b[?25hRequirement already satisfied: six>=1.5.2 in /usr/local/lib/python3.7/dist-packages (from grpcio>=1.28.1->ray) (1.15.0)\n",
      "Requirement already satisfied: packaging>=20.4 in /usr/local/lib/python3.7/dist-packages (from redis>=3.5.0->ray) (21.3)\n",
      "Requirement already satisfied: importlib-metadata>=1.0 in /usr/local/lib/python3.7/dist-packages (from redis>=3.5.0->ray) (4.11.2)\n",
      "Collecting deprecated>=1.2.3\n",
      "  Downloading Deprecated-1.2.13-py2.py3-none-any.whl (9.6 kB)\n",
      "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.7/dist-packages (from deprecated>=1.2.3->redis>=3.5.0->ray) (1.13.3)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=1.0->redis>=3.5.0->ray) (3.7.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=1.0->redis>=3.5.0->ray) (3.10.0.2)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.4->redis>=3.5.0->ray) (3.0.7)\n",
      "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema->ray) (0.18.1)\n",
      "Requirement already satisfied: importlib-resources>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema->ray) (5.4.0)\n",
      "Installing collected packages: deprecated, redis, ray\n",
      "Successfully installed deprecated-1.2.13 ray-1.10.0 redis-4.1.4\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import copy\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import scipy\n",
    "\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
    "\n",
    "import torch\n",
    "torch.manual_seed(2)\n",
    "np.random.seed(2)\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader, SubsetRandomSampler, SequentialSampler\n",
    "import torchvision.models as models\n",
    "!pip install torchinfo\n",
    "!pip install torchattacks\n",
    "!pip install pip install grad-cam\n",
    "!pip install ray\n",
    "from torchinfo import summary\n",
    "from torchvision.models.resnet import _resnet,BasicBlock\n",
    "import torchattacks\n",
    "import torchvision.utils\n",
    "import torch.nn.functional as F\n",
    "from pytorch_grad_cam import GradCAM\n",
    "from ray import tune\n",
    "from ray.tune import CLIReporter\n",
    "from ray.tune.schedulers import ASHAScheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122,
     "referenced_widgets": [
      "1de22a097bdd4ed18637e8ff9b5cd8ee",
      "26fd65390e934a8ab441a4fd6c53e275",
      "7baa3c40ce0b47449a2672e8fde1b39a",
      "07ca3b83b47f43dd82f49e0652de9627",
      "8e87dcaf35074494bd4607a41f50331a",
      "ac0705eefaa44dd5ba17ff4b3e727c1a",
      "acdebbc53d2a4b8a9730c83838b09b93",
      "2519d73fef1a428d88fdaa01032525e2",
      "3d4d1725f2984182823214956c7a86db",
      "bb17f1afd6994c1391d0271a2049fd3b",
      "5394197ac14946a29a8d7a32c394d780"
     ]
    },
    "executionInfo": {
     "elapsed": 22092,
     "status": "ok",
     "timestamp": 1646737988360,
     "user": {
      "displayName": "khiem nguyen trong",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "06117067585511458128"
     },
     "user_tz": -60
    },
    "id": "o591An4WNqf8",
    "outputId": "da291564-f0ee-4bfa-e8d4-941127e60f8d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1de22a097bdd4ed18637e8ff9b5cd8ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/170498071 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose([\n",
    "# transforms.Resize((224)),\n",
    "transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(\n",
    "root='./data', train=True, download=True, transform=transform)\n",
    "\n",
    "valset = torchvision.datasets.CIFAR10(\n",
    "    root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(\n",
    "    root='./data', train=False, download=True, transform=transform)\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer',\n",
    "        'dog', 'frog', 'horse', 'ship', 'truck')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oAVdFwYZai_7"
   },
   "outputs": [],
   "source": [
    "from torch.nn import Conv2d,AvgPool2d,Linear,Sequential,Dropout,BatchNorm2d,ModuleList,BatchNorm1d\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import math\n",
    "from torch.autograd import Variable\n",
    "from functools import partial\n",
    "\n",
    "class BasicConv(nn.Module):\n",
    "    def __init__(self, in_planes, out_planes, kernel_size, stride=1, padding=0, dilation=1, groups=1, relu=True, bn=True, bias=False):\n",
    "        super(BasicConv, self).__init__()\n",
    "        self.out_channels = out_planes\n",
    "        self.conv = nn.Conv2d(in_planes, out_planes, kernel_size=kernel_size, stride=stride, padding=padding, dilation=dilation, groups=groups, bias=bias)\n",
    "        self.bn = nn.BatchNorm2d(out_planes,eps=1e-5, momentum=0.01, affine=True) if bn else None\n",
    "        self.relu = nn.ReLU() if relu else None\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        if self.bn is not None:\n",
    "            x = self.bn(x)\n",
    "        if self.relu is not None:\n",
    "            x = self.relu(x)\n",
    "        return x\n",
    "\n",
    "class Flatten(nn.Module):\n",
    "    def forward(self, x):\n",
    "        return x.view(x.size(0), -1)\n",
    "\n",
    "class ChannelGate(nn.Module):\n",
    "    def __init__(self, gate_channels, reduction_ratio=16, pool_types=['avg', 'max']):\n",
    "        super(ChannelGate, self).__init__()\n",
    "        self.gate_channels = gate_channels\n",
    "        self.mlp = nn.Sequential(\n",
    "            Flatten(),\n",
    "            nn.Linear(gate_channels, gate_channels // reduction_ratio),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(gate_channels // reduction_ratio, gate_channels)\n",
    "            )\n",
    "        self.pool_types = pool_types\n",
    "    def forward(self, x):\n",
    "        channel_att_sum = None\n",
    "        for pool_type in self.pool_types:\n",
    "            if pool_type=='avg':\n",
    "                avg_pool = F.avg_pool2d( x, (x.size(2), x.size(3)), stride=(x.size(2), x.size(3)))\n",
    "                channel_att_raw = self.mlp( avg_pool )\n",
    "            elif pool_type=='max':\n",
    "                max_pool = F.max_pool2d( x, (x.size(2), x.size(3)), stride=(x.size(2), x.size(3)))\n",
    "                channel_att_raw = self.mlp( max_pool )\n",
    "\n",
    "            if channel_att_sum is None:\n",
    "                channel_att_sum = channel_att_raw\n",
    "            else:\n",
    "                channel_att_sum = channel_att_sum + channel_att_raw\n",
    "\n",
    "        scale = torch.sigmoid( channel_att_sum ).unsqueeze(2).unsqueeze(3).expand_as(x)\n",
    "        return x * scale\n",
    "\n",
    "def logsumexp_2d(tensor):\n",
    "    tensor_flatten = tensor.view(tensor.size(0), tensor.size(1), -1)\n",
    "    s, _ = torch.max(tensor_flatten, dim=2, keepdim=True)\n",
    "    outputs = s + (tensor_flatten - s).exp().sum(dim=2, keepdim=True).log()\n",
    "    return outputs\n",
    "\n",
    "class ChannelPool(nn.Module):\n",
    "    def forward(self, x):\n",
    "        return torch.cat( (torch.max(x,1)[0].unsqueeze(1), torch.mean(x,1).unsqueeze(1)), dim=1 )\n",
    "\n",
    "class SpatialGate(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SpatialGate, self).__init__()\n",
    "        kernel_size = 7\n",
    "        self.compress = ChannelPool()\n",
    "        self.spatial = BasicConv(2, 1, kernel_size, stride=1, padding=(kernel_size-1) // 2, relu=False)\n",
    "    def forward(self, x):\n",
    "        x_compress = self.compress(x)\n",
    "        x_out = self.spatial(x_compress)\n",
    "        scale = torch.sigmoid(x_out) # broadcasting\n",
    "        return x * scale\n",
    "\n",
    "class CBAM(nn.Module):\n",
    "    def __init__(self, gate_channels, reduction_ratio=16, pool_types=['avg', 'max'], no_spatial=False):\n",
    "        super(CBAM, self).__init__()\n",
    "        self.ChannelGate = ChannelGate(gate_channels, reduction_ratio, pool_types)\n",
    "        self.no_spatial=no_spatial\n",
    "        if not no_spatial:\n",
    "            self.SpatialGate = SpatialGate()\n",
    "    def forward(self, x):\n",
    "        x_out = self.ChannelGate(x)\n",
    "        if not self.no_spatial:\n",
    "            x_out = self.SpatialGate(x_out)\n",
    "        return x_out\n",
    "\n",
    "class Base(nn.Module):\n",
    "    def freeze(self):\n",
    "        for param in self.base_model.parameters():\n",
    "                param.requires_grad = False\n",
    "    \n",
    "    def unfreeze(self):\n",
    "        for param in self.base_model.parameters():\n",
    "                param.requires_grad = True\n",
    "    \n",
    "    def attach_fea_out(self,classname,input,output):\n",
    "        self.features.append(output)\n",
    "\n",
    "    def attach_fea_in(self,classname,input,output):\n",
    "        self.features.append(input[0])\n",
    "\n",
    "    def __init__(self,trainable = True,attention=False,base=18):\n",
    "        super(Base,self).__init__()\n",
    "        self.features = []\n",
    "        self.channel_size = []\n",
    "        print(base)\n",
    "        if base == 9:\n",
    "            self.base_model = _resnet('resnet', BasicBlock, [1, 1, 1, 1], False, True)\n",
    "        elif base==18:\n",
    "            self.base_model = models.resnet18(pretrained=False)\n",
    "        else:\n",
    "            self.base_model = models.resnet34(pretrained=False)\n",
    "\n",
    "        used_blocks = ['layer1', 'layer2','layer3','layer4']\n",
    "        unused_blocks = ['avgpool','fc']\n",
    "\n",
    "        for block in used_blocks:\n",
    "            getattr(self.base_model,block).register_forward_hook(self.attach_fea_out)\n",
    "\n",
    "        for block in unused_blocks:\n",
    "             setattr(self.base_model,block,nn.Identity())\n",
    "        \n",
    "        if not trainable:\n",
    "            self.freeze()\n",
    "\n",
    "        fake_img = torch.rand(1,3,256,256) ## pass fake img to the model to get the channel size of each inception block\n",
    "        self.base_model(fake_img)\n",
    "        self.channel_size = [block.size()[1] for block in self.features]\n",
    "        self.features = []\n",
    "\n",
    "    def forward(self,img):\n",
    "        self.base_model(img)\n",
    "\n",
    "    def get_MLSP(self,img,feature_type,resize = True):\n",
    "        self.base_model(img)\n",
    "        if resize:\n",
    "            print(resize)\n",
    "            if feature_type == 'narrow':\n",
    "                MLSP = [F.adaptive_avg_pool2d(block, (1, 1)) for block in self.features]\n",
    "                for i in range(len(MLSP)):\n",
    "                    MLSP[i] = MLSP[i].squeeze(2).squeeze(2)\n",
    "\n",
    "            if feature_type == 'wide':\n",
    "                MLSP = [F.interpolate(block,mode = 'bilinear', size = 7) for block in self.features]\n",
    "            \n",
    "            MLSP = torch.cat(MLSP,dim = 1)\n",
    "            self.features = []\n",
    "        else:\n",
    "            MLSP = self.features\n",
    "            self.features = []\n",
    "        return MLSP\n",
    "\n",
    "\n",
    "\n",
    "class Head(nn.Module):\n",
    "    dp = 0.5\n",
    "    def conv_block(self,inc,outc,ker,padding = 1,avgpool = False):\n",
    "        modules = []\n",
    "        modules.append(nn.Dropout(Head.dp))\n",
    "        if avgpool:\n",
    "            modules.append(AvgPool2d(3,1,1))\n",
    "        modules.append(Conv2d(inc,outc,ker,padding = padding))\n",
    "        modules.append(nn.BatchNorm2d(outc))\n",
    "        modules.append(nn.ReLU())\n",
    "        return Sequential(*modules)\n",
    "\n",
    "    def __init__(self,head_type,num_channel):\n",
    "        super(Head, self).__init__()\n",
    "        self.head_type = head_type\n",
    "        self.num_ch = num_channel\n",
    "\n",
    "        if head_type == 'mlsp_cnn_gap_attn':\n",
    "            self.attn = []\n",
    "            self.conv = []\n",
    "            for i in range(4):\n",
    "                if i!=3:\n",
    "                    self.attn.append(CBAM(num_channel[i],reduction_ratio=16))\n",
    "                else:\n",
    "                    self.attn.append(CBAM(num_channel[i],reduction_ratio=16,no_spatial=True))\n",
    "                self.conv.append(Sequential(\n",
    "                                    self.conv_block(num_channel[i],num_channel[i],1,0),\n",
    "                                    self.conv_block(num_channel[i],num_channel[i],3,1),\n",
    "                          ))\n",
    "            self.attn = ModuleList(self.attn)\n",
    "            self.conv = ModuleList(self.conv)\n",
    "        self.dense = Sequential(Linear(960,10))\n",
    "\n",
    "    def forward(self,features):\n",
    "        if self.head_type == 'mlsp_gap':\n",
    "            x = torch.cat([F.adaptive_avg_pool2d(feature, (1, 1)) for feature in features],dim=1)\n",
    "        else:\n",
    "            x = torch.cat([F.adaptive_avg_pool2d(block2(block1(feature)+feature),(1,1)) for feature,block1,block2 in zip(features,self.attn,self.conv)],dim=1)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.dense(x)\n",
    "        return x\n",
    "\n",
    "class Fmodel(nn.Module):\n",
    "    def __init__(self, head_type='mlsp_gap',base = 18,dp = 0.5):\n",
    "        super(Fmodel,self).__init__()\n",
    "        self.bmodel = Base(base=base)\n",
    "        Head.dp = dp\n",
    "        self.head = Head(head_type,self.bmodel.channel_size)\n",
    "        self.feature_type = 'narrow'    \n",
    "        self.resize = False\n",
    "        self.fea = []\n",
    "        self.gap_fea = []\n",
    "        self.gradient = []\n",
    "        self.handles = []\n",
    "        \n",
    "    def forward(self,img):\n",
    "        x = self.bmodel.get_MLSP(img,self.feature_type,self.resize)\n",
    "        x = self.head(x)\n",
    "        return x\n",
    "\n",
    "    def unfreeze(self):\n",
    "        self.bmodel.unfreeze()\n",
    "    \n",
    "    def freeze(self):\n",
    "        self.bmodel.freeze()\n",
    "\n",
    "    def hook_gap(self):\n",
    "        handle = self.head.dense.register_forward_hook(lambda layer, inl, _,: self.gap_fea.append(inl[0]))\n",
    "        self.handles += [handle]\n",
    "        return handle\n",
    "\n",
    "    def hook_grad(self):\n",
    "        handle = []\n",
    "        handle.append(self.head.conv[0].register_full_backward_hook(lambda layer, inl, out,: self.gradient.append(out[0])))\n",
    "        handle.append(self.head.conv[1].register_full_backward_hook(lambda layer, inl, out,: self.gradient.append(out[0])))\n",
    "        handle.append(self.head.conv[2].register_full_backward_hook(lambda layer, inl, out,: self.gradient.append(out[0])))\n",
    "        handle.append(self.head.conv[3].register_full_backward_hook(lambda layer, inl, out,: self.gradient.append(out[0])))\n",
    "        self.handles += handle\n",
    "        return handle\n",
    "\n",
    "    def hook_fea(self):\n",
    "        handle = []\n",
    "        handle.append(self.head.conv[0].register_forward_hook(lambda layer, inl, out,: self.fea.append(out)))\n",
    "        handle.append(self.head.conv[1].register_forward_hook(lambda layer, inl, out,: self.fea.append(out)))\n",
    "        handle.append(self.head.conv[2].register_forward_hook(lambda layer, inl, out,: self.fea.append(out)))\n",
    "        handle.append(self.head.conv[3].register_forward_hook(lambda layer, inl, out,: self.fea.append(out)))\n",
    "        self.handles += handle\n",
    "        return handle\n",
    "\n",
    "    def hook(self):\n",
    "        self.hook_gap()\n",
    "        self.hook_grad()\n",
    "        self.hook_fea()\n",
    "\n",
    "    def unhook(self):\n",
    "        for fea in self.gap_fea:\n",
    "            fea.detach()\n",
    "        for grad in self.gradient:\n",
    "            grad.detach()\n",
    "        for fea in self.fea:\n",
    "            fea.detach()\n",
    "\n",
    "        self.gap_fea = []\n",
    "        self.gradient = []\n",
    "        self.fea = []\n",
    "\n",
    "        for h in self.handles:\n",
    "            h.remove()\n",
    "        self.handles = []\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3gKqBY49_ZGX"
   },
   "outputs": [],
   "source": [
    "def grad_cam(model, preds, label,ind,ind_ad):\n",
    "    masks_attn_ori = []\n",
    "    masks_attn_adv = []\n",
    "\n",
    "\n",
    "    preds[torch.arange(len(preds)),label].sum().backward(retain_graph=True)\n",
    "    mse = torch.nn.MSELoss()\n",
    "    loss = 0\n",
    "    model.gradient = model.gradient[::-1]\n",
    "    for i in range(4):\n",
    "        weight = model.gradient[i].mean(dim=-1, keepdim=True).mean(dim=-2, keepdim=True)\n",
    "        mask = weight * model.fea[i]\n",
    "        mask_ori = F.relu(mask[ind].sum(dim=1))\n",
    "        masks_attn_ori.append(mask_ori)\n",
    "        \n",
    "        mask_adv = F.relu(mask[ind_ad].sum(dim=1))      \n",
    "        masks_attn_adv.append(mask_adv)\n",
    "\n",
    "    model.zero_grad()\n",
    "    for i in range(4):\n",
    "        loss += mse(masks_attn_ori[i],masks_attn_adv[i])\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZlTzZbOr8ItD"
   },
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm, trange\n",
    "import torchattacks\n",
    "\n",
    "def train_cifar(config, checkpoint_dir=None, data_dir=None):\n",
    "    trainset = torchvision.datasets.CIFAR10(\n",
    "    root='./data', train=True, download=True, transform=transform)\n",
    "\n",
    "    valset = torchvision.datasets.CIFAR10(\n",
    "        root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "\n",
    "    testset = torchvision.datasets.CIFAR10(\n",
    "        root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "    test_loader = torch.utils.data.DataLoader(\n",
    "        testset, batch_size=64, shuffle=False, num_workers=2, sampler = SequentialSampler(testset.data[5000:10000]),pin_memory=True)\n",
    "    \n",
    "    num_epochs = 15 #50\n",
    "    adv = True\n",
    "    dense_l2 = True\n",
    "    model = Fmodel('mlsp_cnn_gap_attn',18,config['dp'])\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=config['lr'], weight_decay=config['l2'])\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer,factor=0.1, patience=1, verbose=True, min_lr =1e-6)\n",
    "    train_loader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True, num_workers=2,pin_memory=True)\n",
    "    val_loader = torch.utils.data.DataLoader(valset, batch_size=64, shuffle=False, num_workers=2, sampler = SequentialSampler(valset.data[5000:10000]),pin_memory=True)\n",
    "    dataloaders = {\"train\": train_loader, \"val\": val_loader}\n",
    "\n",
    "    if checkpoint_dir:\n",
    "        model_state, optimizer_state = torch.load(\n",
    "            os.path.join(checkpoint_dir, \"checkpoint\"))\n",
    "        model.load_state_dict(model_state)\n",
    "        optimizer.load_state_dict(optimizer_state)\n",
    "    since = time.time()\n",
    "    best_loss = 1000.0\n",
    "    atk = torchattacks.PGD(model, eps=8/255, alpha=2/225, steps=7, random_start=True)\n",
    "    atk_fgsm = torchattacks.FGSM(model, eps=8/255)\n",
    "    \n",
    "    print('Config: ', config)\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "\n",
    "        for phase in ['train', 'val']: # Each epoch has a training and validation phase\n",
    "            if phase == 'train':\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "            size = 0\n",
    "\n",
    "            iterator = iter(dataloaders[phase])\n",
    "            for _ in range(len(iterator)): # Iterate over data\n",
    "                inputs, labels = next(iterator)\n",
    "                if adv:\n",
    "                    if attn_pre or ada_reg:\n",
    "                            inputs = torch.cat((inputs.to(device), atk(inputs, labels)),dim=0)\n",
    "                            labels = torch.cat((labels,labels),dim=0)\n",
    "                            ind = list(range(len(inputs)//2))\n",
    "                            ind_ad = list(range(len(inputs)//2,len(inputs)))\n",
    "                    else:\n",
    "                        ind_ad = np.random.choice(len(inputs),len(inputs)//2,replace=False)\n",
    "                        ind = np.delete(np.arange(len(inputs)),ind_ad)\n",
    "                        inputs_adv = atk(inputs[ind_ad], labels[ind_ad])\n",
    "                        inputs = inputs.to(device)\n",
    "                        inputs[ind_ad] = inputs_adv\n",
    "\n",
    "                else:\n",
    "                    inputs = inputs.to(device)\n",
    "\n",
    "                inputs = transforms.functional.normalize(inputs,(0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
    "                labels = labels.to(device)\n",
    "                optimizer.zero_grad() # Zero the parameter gradients\n",
    "\n",
    "                with torch.set_grad_enabled(phase == 'train'): # Forward. Track history if only in train\n",
    "                    \n",
    "                    if phase == 'train': # Backward + optimize only if in training phase\n",
    "                        if dense_l2:\n",
    "                            model.hook()\n",
    "                        outputs = model(inputs)\n",
    "                        loss = (config['adv_weight']*criterion(outputs[ind], labels[ind]) + (1-config['adv_weight'])*criterion(outputs[ind_ad], labels[ind_ad]))                           \n",
    "                        _, preds = torch.max(outputs, 1)\n",
    "                        loss_pres = grad_cam(model, outputs,labels,ind,ind_ad)\n",
    "                        if not torch.isnan(loss_pres).any():\n",
    "                            loss = config['scale']*loss + (1-config['scale'])*loss_pres\n",
    "                        else:\n",
    "                            print('nan')\n",
    "\n",
    "                        if dense_l2:\n",
    "                            fea = model.gap_fea[0]\n",
    "                            out_ori = fea[ind]\n",
    "                            out_adv = fea[ind_ad]\n",
    "                            diff = (out_adv-out_ori).abs().mean(axis=0).reshape(out_ori.shape[-1])\n",
    "                            diff = (diff - diff.min())/(diff.max()-diff.min()+1e-9)*config['ada_reg']\n",
    "                            loss += (diff*((model.head.dense[0].weight)**2).sum(dim=0)).sum()\n",
    "\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "                        if dense_l2:\n",
    "                            model.unhook()\n",
    "                    \n",
    "                    if phase == 'val':\n",
    "                        outputs = model(inputs)\n",
    "                        loss = criterion(outputs, labels)\n",
    "                        _, preds = torch.max(outputs, 1)\n",
    "\n",
    "                \n",
    "                # Statistics\n",
    "                \n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "                size+=len(preds)\n",
    "\n",
    "            epoch_loss = running_loss / size\n",
    "            \n",
    "            \n",
    "            if phase == 'train': # Adjust learning rate based on val loss\n",
    "                scheduler.step(epoch_loss)\n",
    "                \n",
    "            epoch_acc = running_corrects.double() / size\n",
    "            #print('{} Loss: {:.3f} Loss2: {:.3f} Acc: {:.3f}'.format(phase, epoch_loss, np.mean(loss2_his), epoch_acc))\n",
    "            # deep copy the model\n",
    "            if phase == 'val' and epoch_loss < best_loss:\n",
    "                best_loss = epoch_loss\n",
    "                print('Best loss: ', best_loss)\n",
    "            if phase == 'val':\n",
    "                with tune.checkpoint_dir(epoch) as checkpoint_dir:\n",
    "                    path = os.path.join(checkpoint_dir, \"checkpoint\")\n",
    "                    torch.save((model.state_dict(), optimizer.state_dict()), path)\n",
    "\n",
    "                tune.report(loss=epoch_loss, accuracy=epoch_acc)\n",
    "\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best_loss: {:4f}'.format(best_loss))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5alGcZ-7PHEU",
    "outputId": "c386d14a-3c34-425c-e216-454b0c101be1"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-08 11:13:53,646\tWARNING experiment.py:256 -- No name detected on trainable. Using DEFAULT.\n",
      "2022-03-08 11:13:53,656\tINFO registry.py:70 -- Detected unknown callable for trainable. Converting to class.\n",
      "2022-03-08 11:13:53,807\tWARNING callback.py:115 -- The TensorboardX logger cannot be instantiated because either TensorboardX or one of it's dependencies is not installed. Please make sure you have the latest version of TensorboardX installed: `pip install -U tensorboardx`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(func pid=298)\u001b[0m Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(func pid=298)\u001b[0m \r",
      "  0%|          | 0/170498071 [00:00<?, ?it/s]\n",
      "  0%|          | 1024/170498071 [00:00<7:49:41, 6049.89it/s]\n",
      "  0%|          | 33792/170498071 [00:00<24:42, 115000.76it/s]\n",
      "  0%|          | 82944/170498071 [00:00<14:43, 192969.96it/s]\n",
      "  0%|          | 214016/170498071 [00:00<06:48, 417260.53it/s]\n",
      "  0%|          | 443392/170498071 [00:00<03:47, 746970.57it/s]\n",
      "  1%|          | 902144/170498071 [00:01<02:01, 1398121.19it/s]\n",
      "  1%|          | 1819648/170498071 [00:01<01:02, 2677636.47it/s]\n",
      "  2%|▏         | 3671040/170498071 [00:01<00:31, 5240091.31it/s]\n",
      "  4%|▍         | 6800384/170498071 [00:01<00:17, 9269495.49it/s]\n",
      "  6%|▌         | 9946112/170498071 [00:01<00:13, 11987326.38it/s]\n",
      "  8%|▊         | 12960768/170498071 [00:01<00:11, 13718441.43it/s]\n",
      "  9%|▉         | 16090112/170498071 [00:02<00:10, 15034888.86it/s]\n",
      " 11%|█         | 18606080/170498071 [00:02<00:08, 17070111.68it/s]\n",
      " 12%|█▏        | 20416512/170498071 [00:02<00:09, 16575538.69it/s]\n",
      " 13%|█▎        | 22137856/170498071 [00:02<00:09, 15357248.77it/s]\n",
      " 14%|█▍        | 24544256/170498071 [00:02<00:09, 15238135.91it/s]\n",
      " 16%|█▌        | 27640832/170498071 [00:02<00:09, 15748788.04it/s]\n",
      " 18%|█▊        | 30704640/170498071 [00:02<00:08, 16240967.01it/s]\n",
      " 20%|█▉        | 33801216/170498071 [00:03<00:08, 16742321.06it/s]\n",
      " 22%|██▏       | 36865024/170498071 [00:03<00:07, 17056258.28it/s]\n",
      " 23%|██▎       | 39928832/170498071 [00:03<00:07, 17246976.98it/s]\n",
      " 25%|██▌       | 42959872/170498071 [00:03<00:07, 17299328.71it/s]\n",
      " 27%|██▋       | 46007296/170498071 [00:03<00:07, 17407665.60it/s]\n",
      " 29%|██▉       | 49087488/170498071 [00:03<00:06, 17546564.54it/s]\n",
      " 31%|███       | 52200448/170498071 [00:04<00:06, 17664462.17it/s]\n",
      " 32%|███▏      | 55215104/170498071 [00:04<00:06, 17644881.54it/s]\n",
      " 34%|███▍      | 58164224/170498071 [00:04<00:06, 17484664.68it/s]\n",
      " 36%|███▌      | 61015040/170498071 [00:04<00:06, 17202997.08it/s]\n",
      " 37%|███▋      | 63882240/170498071 [00:04<00:06, 17033576.77it/s]\n",
      " 39%|███▉      | 66880512/170498071 [00:05<00:06, 17069401.33it/s]\n",
      " 41%|████      | 69944320/170498071 [00:05<00:05, 17282124.21it/s]\n",
      " 43%|████▎     | 72877056/170498071 [00:05<00:05, 17201482.84it/s]\n",
      " 44%|████▍     | 75744256/170498071 [00:05<00:05, 17015269.71it/s]\n",
      " 46%|████▌     | 78693376/170498071 [00:05<00:05, 16961268.32it/s]\n",
      " 48%|████▊     | 81691648/170498071 [00:05<00:05, 17090292.86it/s]\n",
      " 50%|████▉     | 84755456/170498071 [00:06<00:04, 17269607.07it/s]\n",
      " 51%|█████▏    | 87786496/170498071 [00:06<00:04, 17300685.72it/s]\n",
      " 53%|█████▎    | 90850304/170498071 [00:06<00:04, 17439709.92it/s]\n",
      " 55%|█████▍    | 93668352/170498071 [00:06<00:04, 17114591.52it/s]\n",
      " 57%|█████▋    | 96650240/170498071 [00:06<00:04, 17167726.16it/s]\n",
      " 58%|█████▊    | 99697664/170498071 [00:06<00:04, 17293790.60it/s]\n",
      " 60%|██████    | 102745088/170498071 [00:07<00:03, 17403183.68it/s]\n",
      " 62%|██████▏   | 105661440/170498071 [00:07<00:03, 17257550.64it/s]\n",
      " 64%|██████▍   | 108758016/170498071 [00:07<00:03, 17463956.54it/s]\n",
      " 65%|██████▌   | 111589376/170498071 [00:07<00:03, 19621470.14it/s]\n",
      " 67%|██████▋   | 113661952/170498071 [00:07<00:03, 18291816.88it/s]\n",
      " 68%|██████▊   | 115560448/170498071 [00:07<00:03, 17594375.33it/s]\n",
      " 69%|██████▉   | 117670912/170498071 [00:07<00:03, 16203811.98it/s]\n",
      " 71%|███████   | 120679424/170498071 [00:08<00:02, 19368139.22it/s]\n",
      " 72%|███████▏  | 122742784/170498071 [00:08<00:02, 17381248.34it/s]\n",
      " 73%|███████▎  | 124590080/170498071 [00:08<00:02, 16211138.46it/s]\n",
      " 74%|███████▍  | 126829568/170498071 [00:08<00:02, 16574823.14it/s]\n",
      " 76%|███████▌  | 129565696/170498071 [00:08<00:02, 18812279.30it/s]\n",
      " 77%|███████▋  | 131524608/170498071 [00:08<00:02, 17754089.14it/s]\n",
      " 78%|███████▊  | 133355520/170498071 [00:08<00:02, 16949897.72it/s]\n",
      " 79%|███████▉  | 135480320/170498071 [00:09<00:02, 15646704.01it/s]\n",
      " 81%|████████▏ | 138544128/170498071 [00:09<00:01, 16352858.49it/s]\n",
      " 83%|████████▎ | 141591552/170498071 [00:09<00:01, 16791503.15it/s]\n",
      " 85%|████████▍ | 144140288/170498071 [00:09<00:01, 18618406.32it/s]\n",
      " 86%|████████▌ | 146076672/170498071 [00:09<00:01, 17744528.87it/s]\n",
      " 87%|████████▋ | 147897344/170498071 [00:09<00:01, 16698945.08it/s]\n",
      " 88%|████████▊ | 150127616/170498071 [00:09<00:01, 15621001.64it/s]\n",
      " 90%|████████▉ | 153175040/170498071 [00:10<00:01, 16322829.26it/s]\n",
      " 92%|█████████▏| 156238848/170498071 [00:10<00:00, 16795155.95it/s]\n",
      " 93%|█████████▎| 159335424/170498071 [00:10<00:00, 17168137.96it/s]\n",
      " 95%|█████████▌| 162382848/170498071 [00:10<00:00, 17292738.50it/s]\n",
      " 97%|█████████▋| 165266432/170498071 [00:10<00:00, 17110407.17it/s]\n",
      "170499072it [00:10, 15548277.13it/s]                               \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(func pid=298)\u001b[0m Extracting ./data/cifar-10-python.tar.gz to ./data\n",
      "\u001b[2m\u001b[36m(func pid=298)\u001b[0m Files already downloaded and verified\n",
      "\u001b[2m\u001b[36m(func pid=298)\u001b[0m Files already downloaded and verified\n",
      "\u001b[2m\u001b[36m(func pid=298)\u001b[0m 18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(func pid=298)\u001b[0m E0308 11:14:22.415531481     380 fork_posix.cc:70]           Fork support is only compatible with the epoll1 and poll polling strategies\n",
      "\u001b[2m\u001b[36m(func pid=298)\u001b[0m E0308 11:14:22.438941128     380 fork_posix.cc:70]           Fork support is only compatible with the epoll1 and poll polling strategies\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(func pid=298)\u001b[0m Config:  {'dp': 0.2, 'l2': 0.0002714992481279903, 'ada_reg': 0.002018363174302323, 'adv_weight': 0.6306034330529589, 'scale': 0.4530136484753278, 'lr': 0.0015223506791380115}\n",
      "\u001b[2m\u001b[36m(func pid=298)\u001b[0m Epoch 0/14\n",
      "\u001b[2m\u001b[36m(func pid=298)\u001b[0m ----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(func pid=298)\u001b[0m E0308 11:22:24.606243623     380 fork_posix.cc:70]           Fork support is only compatible with the epoll1 and poll polling strategies\n",
      "\u001b[2m\u001b[36m(func pid=298)\u001b[0m E0308 11:22:24.625895980     380 fork_posix.cc:70]           Fork support is only compatible with the epoll1 and poll polling strategies\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(func pid=298)\u001b[0m Best loss:  1.4819137649536134\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-08 11:22:42,646\tWARNING util.py:164 -- The `fetch_result` operation took 2.589 s, which may be a performance bottleneck.\n",
      "2022-03-08 11:22:42,682\tWARNING util.py:164 -- The `process_trial` operation took 2.625 s, which may be a performance bottleneck.\n",
      "\u001b[2m\u001b[36m(func pid=298)\u001b[0m E0308 11:22:42.696280471     380 fork_posix.cc:70]           Fork support is only compatible with the epoll1 and poll polling strategies\n",
      "\u001b[2m\u001b[36m(func pid=298)\u001b[0m E0308 11:22:42.717680508     380 fork_posix.cc:70]           Fork support is only compatible with the epoll1 and poll polling strategies\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(func pid=298)\u001b[0m Epoch 1/14\n",
      "\u001b[2m\u001b[36m(func pid=298)\u001b[0m ----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(func pid=298)\u001b[0m E0308 11:30:41.875155584     380 fork_posix.cc:70]           Fork support is only compatible with the epoll1 and poll polling strategies\n",
      "\u001b[2m\u001b[36m(func pid=298)\u001b[0m E0308 11:30:41.896666914     380 fork_posix.cc:70]           Fork support is only compatible with the epoll1 and poll polling strategies\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(func pid=298)\u001b[0m Best loss:  1.4715185634613037\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(func pid=298)\u001b[0m E0308 11:30:57.216997416     380 fork_posix.cc:70]           Fork support is only compatible with the epoll1 and poll polling strategies\n",
      "\u001b[2m\u001b[36m(func pid=298)\u001b[0m E0308 11:30:57.240582520     380 fork_posix.cc:70]           Fork support is only compatible with the epoll1 and poll polling strategies\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(func pid=298)\u001b[0m Epoch 2/14\n",
      "\u001b[2m\u001b[36m(func pid=298)\u001b[0m ----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(func pid=298)\u001b[0m E0308 11:38:53.152749559     380 fork_posix.cc:70]           Fork support is only compatible with the epoll1 and poll polling strategies\n",
      "\u001b[2m\u001b[36m(func pid=298)\u001b[0m E0308 11:38:53.172838331     380 fork_posix.cc:70]           Fork support is only compatible with the epoll1 and poll polling strategies\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(func pid=298)\u001b[0m Best loss:  1.163822728729248\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(func pid=298)\u001b[0m E0308 11:39:08.428880144     380 fork_posix.cc:70]           Fork support is only compatible with the epoll1 and poll polling strategies\n",
      "\u001b[2m\u001b[36m(func pid=298)\u001b[0m E0308 11:39:08.452136623     380 fork_posix.cc:70]           Fork support is only compatible with the epoll1 and poll polling strategies\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(func pid=298)\u001b[0m Epoch 3/14\n",
      "\u001b[2m\u001b[36m(func pid=298)\u001b[0m ----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(func pid=298)\u001b[0m E0308 11:47:08.503680132     380 fork_posix.cc:70]           Fork support is only compatible with the epoll1 and poll polling strategies\n",
      "\u001b[2m\u001b[36m(func pid=298)\u001b[0m E0308 11:47:08.524536721     380 fork_posix.cc:70]           Fork support is only compatible with the epoll1 and poll polling strategies\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(func pid=298)\u001b[0m Best loss:  1.1071286731719971\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(func pid=298)\u001b[0m E0308 11:47:23.984585337     380 fork_posix.cc:70]           Fork support is only compatible with the epoll1 and poll polling strategies\n",
      "\u001b[2m\u001b[36m(func pid=298)\u001b[0m E0308 11:47:24.007980160     380 fork_posix.cc:70]           Fork support is only compatible with the epoll1 and poll polling strategies\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(func pid=298)\u001b[0m Epoch 4/14\n",
      "\u001b[2m\u001b[36m(func pid=298)\u001b[0m ----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(func pid=298)\u001b[0m E0308 11:55:23.426851388     380 fork_posix.cc:70]           Fork support is only compatible with the epoll1 and poll polling strategies\n",
      "\u001b[2m\u001b[36m(func pid=298)\u001b[0m E0308 11:55:23.450341745     380 fork_posix.cc:70]           Fork support is only compatible with the epoll1 and poll polling strategies\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(func pid=298)\u001b[0m Best loss:  1.0277284984588624\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(func pid=298)\u001b[0m E0308 11:55:38.807181567     380 fork_posix.cc:70]           Fork support is only compatible with the epoll1 and poll polling strategies\n",
      "\u001b[2m\u001b[36m(func pid=298)\u001b[0m E0308 11:55:38.827636840     380 fork_posix.cc:70]           Fork support is only compatible with the epoll1 and poll polling strategies\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(func pid=298)\u001b[0m Epoch 5/14\n",
      "\u001b[2m\u001b[36m(func pid=298)\u001b[0m ----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(func pid=298)\u001b[0m E0308 12:03:37.522767858     380 fork_posix.cc:70]           Fork support is only compatible with the epoll1 and poll polling strategies\n",
      "\u001b[2m\u001b[36m(func pid=298)\u001b[0m E0308 12:03:37.543669443     380 fork_posix.cc:70]           Fork support is only compatible with the epoll1 and poll polling strategies\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(func pid=298)\u001b[0m Best loss:  0.9731098812103272\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(func pid=298)\u001b[0m E0308 12:03:53.181850789     380 fork_posix.cc:70]           Fork support is only compatible with the epoll1 and poll polling strategies\n",
      "\u001b[2m\u001b[36m(func pid=298)\u001b[0m E0308 12:03:53.203681220     380 fork_posix.cc:70]           Fork support is only compatible with the epoll1 and poll polling strategies\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(func pid=298)\u001b[0m Epoch 6/14\n",
      "\u001b[2m\u001b[36m(func pid=298)\u001b[0m ----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(func pid=298)\u001b[0m E0308 12:11:54.819172620     380 fork_posix.cc:70]           Fork support is only compatible with the epoll1 and poll polling strategies\n",
      "\u001b[2m\u001b[36m(func pid=298)\u001b[0m E0308 12:11:54.838955097     380 fork_posix.cc:70]           Fork support is only compatible with the epoll1 and poll polling strategies\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(func pid=298)\u001b[0m Best loss:  0.916001215171814\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(func pid=298)\u001b[0m E0308 12:12:10.328707610     380 fork_posix.cc:70]           Fork support is only compatible with the epoll1 and poll polling strategies\n",
      "\u001b[2m\u001b[36m(func pid=298)\u001b[0m E0308 12:12:10.354562137     380 fork_posix.cc:70]           Fork support is only compatible with the epoll1 and poll polling strategies\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(func pid=298)\u001b[0m Epoch 7/14\n",
      "\u001b[2m\u001b[36m(func pid=298)\u001b[0m ----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(func pid=298)\u001b[0m E0308 12:20:15.179830923     380 fork_posix.cc:70]           Fork support is only compatible with the epoll1 and poll polling strategies\n",
      "\u001b[2m\u001b[36m(func pid=298)\u001b[0m E0308 12:20:15.201051957     380 fork_posix.cc:70]           Fork support is only compatible with the epoll1 and poll polling strategies\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(func pid=298)\u001b[0m Best loss:  0.8516330413818359\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(func pid=298)\u001b[0m E0308 12:20:30.768933983     380 fork_posix.cc:70]           Fork support is only compatible with the epoll1 and poll polling strategies\n",
      "\u001b[2m\u001b[36m(func pid=298)\u001b[0m E0308 12:20:30.790185686     380 fork_posix.cc:70]           Fork support is only compatible with the epoll1 and poll polling strategies\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(func pid=298)\u001b[0m Epoch 8/14\n",
      "\u001b[2m\u001b[36m(func pid=298)\u001b[0m ----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(func pid=298)\u001b[0m E0308 12:28:33.536339545     380 fork_posix.cc:70]           Fork support is only compatible with the epoll1 and poll polling strategies\n",
      "\u001b[2m\u001b[36m(func pid=298)\u001b[0m E0308 12:28:33.563272150     380 fork_posix.cc:70]           Fork support is only compatible with the epoll1 and poll polling strategies\n",
      "\u001b[2m\u001b[36m(func pid=298)\u001b[0m E0308 12:28:49.149165049     380 fork_posix.cc:70]           Fork support is only compatible with the epoll1 and poll polling strategies\n",
      "\u001b[2m\u001b[36m(func pid=298)\u001b[0m E0308 12:28:49.170630232     380 fork_posix.cc:70]           Fork support is only compatible with the epoll1 and poll polling strategies\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(func pid=298)\u001b[0m Epoch 9/14\n",
      "\u001b[2m\u001b[36m(func pid=298)\u001b[0m ----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(func pid=298)\u001b[0m E0308 12:36:51.250920500     380 fork_posix.cc:70]           Fork support is only compatible with the epoll1 and poll polling strategies\n",
      "\u001b[2m\u001b[36m(func pid=298)\u001b[0m E0308 12:36:51.272289602     380 fork_posix.cc:70]           Fork support is only compatible with the epoll1 and poll polling strategies\n",
      "\u001b[2m\u001b[36m(func pid=298)\u001b[0m E0308 12:37:06.793610857     380 fork_posix.cc:70]           Fork support is only compatible with the epoll1 and poll polling strategies\n",
      "\u001b[2m\u001b[36m(func pid=298)\u001b[0m E0308 12:37:06.817398868     380 fork_posix.cc:70]           Fork support is only compatible with the epoll1 and poll polling strategies\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(func pid=298)\u001b[0m Epoch 10/14\n",
      "\u001b[2m\u001b[36m(func pid=298)\u001b[0m ----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(func pid=298)\u001b[0m E0308 12:45:08.487247211     380 fork_posix.cc:70]           Fork support is only compatible with the epoll1 and poll polling strategies\n",
      "\u001b[2m\u001b[36m(func pid=298)\u001b[0m E0308 12:45:08.509240310     380 fork_posix.cc:70]           Fork support is only compatible with the epoll1 and poll polling strategies\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(func pid=298)\u001b[0m Best loss:  0.8246260431289673\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(func pid=298)\u001b[0m E0308 12:45:24.043976592     380 fork_posix.cc:70]           Fork support is only compatible with the epoll1 and poll polling strategies\n",
      "\u001b[2m\u001b[36m(func pid=298)\u001b[0m E0308 12:45:24.072698373     380 fork_posix.cc:70]           Fork support is only compatible with the epoll1 and poll polling strategies\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(func pid=298)\u001b[0m Epoch 11/14\n",
      "\u001b[2m\u001b[36m(func pid=298)\u001b[0m ----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(func pid=298)\u001b[0m E0308 12:53:24.982446504     380 fork_posix.cc:70]           Fork support is only compatible with the epoll1 and poll polling strategies\n",
      "\u001b[2m\u001b[36m(func pid=298)\u001b[0m E0308 12:53:25.003284931     380 fork_posix.cc:70]           Fork support is only compatible with the epoll1 and poll polling strategies\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(func pid=298)\u001b[0m Best loss:  0.820308931350708\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(func pid=298)\u001b[0m E0308 12:53:40.413953979     380 fork_posix.cc:70]           Fork support is only compatible with the epoll1 and poll polling strategies\n",
      "\u001b[2m\u001b[36m(func pid=298)\u001b[0m E0308 12:53:40.434899201     380 fork_posix.cc:70]           Fork support is only compatible with the epoll1 and poll polling strategies\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(func pid=298)\u001b[0m Epoch 12/14\n",
      "\u001b[2m\u001b[36m(func pid=298)\u001b[0m ----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(func pid=298)\u001b[0m E0308 13:01:39.407699503     380 fork_posix.cc:70]           Fork support is only compatible with the epoll1 and poll polling strategies\n",
      "\u001b[2m\u001b[36m(func pid=298)\u001b[0m E0308 13:01:39.427447454     380 fork_posix.cc:70]           Fork support is only compatible with the epoll1 and poll polling strategies\n",
      "\u001b[2m\u001b[36m(func pid=298)\u001b[0m E0308 13:01:54.776443588     380 fork_posix.cc:70]           Fork support is only compatible with the epoll1 and poll polling strategies\n",
      "\u001b[2m\u001b[36m(func pid=298)\u001b[0m E0308 13:01:54.798854309     380 fork_posix.cc:70]           Fork support is only compatible with the epoll1 and poll polling strategies\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(func pid=298)\u001b[0m Epoch 13/14\n",
      "\u001b[2m\u001b[36m(func pid=298)\u001b[0m ----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(func pid=298)\u001b[0m E0308 13:09:55.420821717     380 fork_posix.cc:70]           Fork support is only compatible with the epoll1 and poll polling strategies\n",
      "\u001b[2m\u001b[36m(func pid=298)\u001b[0m E0308 13:09:55.442393139     380 fork_posix.cc:70]           Fork support is only compatible with the epoll1 and poll polling strategies\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(func pid=298)\u001b[0m Best loss:  0.7734364852905273\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(func pid=298)\u001b[0m E0308 13:10:10.942693588     380 fork_posix.cc:70]           Fork support is only compatible with the epoll1 and poll polling strategies\n",
      "\u001b[2m\u001b[36m(func pid=298)\u001b[0m E0308 13:10:10.967407073     380 fork_posix.cc:70]           Fork support is only compatible with the epoll1 and poll polling strategies\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(func pid=298)\u001b[0m Epoch 14/14\n",
      "\u001b[2m\u001b[36m(func pid=298)\u001b[0m ----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(func pid=298)\u001b[0m E0308 13:18:15.580865361     380 fork_posix.cc:70]           Fork support is only compatible with the epoll1 and poll polling strategies\n",
      "\u001b[2m\u001b[36m(func pid=298)\u001b[0m E0308 13:18:15.603491792     380 fork_posix.cc:70]           Fork support is only compatible with the epoll1 and poll polling strategies\n",
      "2022-03-08 13:18:31,275\tWARNING ray_trial_executor.py:691 -- Over the last 60 seconds, the Tune event loop has been backlogged processing new results. Consider increasing your period of result reporting to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(func pid=701)\u001b[0m Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(func pid=701)\u001b[0m \r",
      "  0%|          | 0/170498071 [00:00<?, ?it/s]\n",
      "  0%|          | 1024/170498071 [00:00<7:49:50, 6048.07it/s]\n",
      "  0%|          | 33792/170498071 [00:00<24:41, 115034.29it/s]\n",
      "  0%|          | 82944/170498071 [00:00<14:43, 192919.72it/s]\n",
      "  0%|          | 214016/170498071 [00:00<06:48, 416678.78it/s]\n",
      "  0%|          | 443392/170498071 [00:00<03:48, 745308.38it/s]\n",
      "  1%|          | 902144/170498071 [00:01<02:01, 1396418.27it/s]\n",
      "  1%|          | 1819648/170498071 [00:01<01:02, 2677603.52it/s]\n",
      "  2%|▏         | 3671040/170498071 [00:01<00:31, 5240842.53it/s]\n",
      "  4%|▍         | 6439936/170498071 [00:01<00:19, 8593506.13it/s]\n",
      "  6%|▌         | 9552896/170498071 [00:01<00:13, 11503628.30it/s]\n",
      "  7%|▋         | 12583936/170498071 [00:01<00:11, 13354794.94it/s]\n",
      "  9%|▉         | 15582208/170498071 [00:02<00:10, 14563966.81it/s]\n",
      " 11%|█         | 18547712/170498071 [00:02<00:09, 15345491.76it/s]\n",
      " 13%|█▎        | 21529600/170498071 [00:02<00:09, 15912294.77it/s]\n",
      " 14%|█▍        | 24462336/170498071 [00:02<00:09, 16178037.81it/s]\n",
      " 16%|█▌        | 27575296/170498071 [00:02<00:08, 16695577.40it/s]\n",
      " 18%|█▊        | 30671872/170498071 [00:02<00:08, 17115652.72it/s]\n",
      " 20%|█▉        | 33604608/170498071 [00:03<00:08, 17050080.90it/s]\n",
      " 22%|██▏       | 36717568/170498071 [00:03<00:07, 17349202.13it/s]\n",
      " 23%|██▎       | 39797760/170498071 [00:03<00:07, 17486026.70it/s]\n",
      " 25%|██▌       | 42796032/170498071 [00:03<00:07, 17453545.23it/s]\n",
      " 27%|██▋       | 45745152/170498071 [00:03<00:06, 19842501.33it/s]\n",
      " 28%|██▊       | 47851520/170498071 [00:03<00:06, 18405468.48it/s]\n",
      " 29%|██▉       | 49771520/170498071 [00:04<00:07, 16567618.60it/s]\n",
      " 30%|███       | 51921920/170498071 [00:04<00:07, 16850474.77it/s]\n",
      " 32%|███▏      | 54461440/170498071 [00:04<00:06, 18657340.88it/s]\n",
      " 33%|███▎      | 56406016/170498071 [00:04<00:06, 17227594.36it/s]\n",
      " 34%|███▍      | 58189824/170498071 [00:04<00:06, 16855781.09it/s]\n",
      " 36%|███▌      | 60736512/170498071 [00:04<00:06, 16377123.76it/s]\n",
      " 37%|███▋      | 63587328/170498071 [00:04<00:05, 19252637.17it/s]\n",
      " 38%|███▊      | 65612800/170498071 [00:04<00:06, 17019684.55it/s]\n",
      " 40%|███▉      | 67416064/170498071 [00:05<00:06, 16844175.12it/s]\n",
      " 41%|████      | 69993472/170498071 [00:05<00:05, 16987301.57it/s]\n",
      " 43%|████▎     | 72484864/170498071 [00:05<00:05, 18901836.06it/s]\n",
      " 44%|████▎     | 74454016/170498071 [00:05<00:05, 17662752.61it/s]\n",
      " 45%|████▍     | 76280832/170498071 [00:05<00:05, 16476414.17it/s]\n",
      " 46%|████▌     | 78840832/170498071 [00:05<00:05, 16547015.20it/s]\n",
      " 48%|████▊     | 81314816/170498071 [00:05<00:04, 18298470.17it/s]\n",
      " 49%|████▉     | 83203072/170498071 [00:05<00:04, 17607955.31it/s]\n",
      " 50%|████▉     | 85001216/170498071 [00:06<00:05, 16503304.01it/s]\n",
      " 51%|█████▏    | 87507968/170498071 [00:06<00:04, 18681051.23it/s]\n",
      " 52%|█████▏    | 89435136/170498071 [00:06<00:04, 17529222.64it/s]\n",
      " 54%|█████▎    | 91236352/170498071 [00:06<00:04, 16146100.36it/s]\n",
      " 55%|█████▌    | 93799424/170498071 [00:06<00:04, 16576008.93it/s]\n",
      " 57%|█████▋    | 96431104/170498071 [00:06<00:03, 18965309.84it/s]\n",
      " 58%|█████▊    | 98400256/170498071 [00:06<00:03, 18048211.39it/s]\n",
      " 59%|█████▉    | 100256768/170498071 [00:06<00:04, 16322583.28it/s]\n",
      " 60%|██████    | 102941696/170498071 [00:07<00:04, 16848112.57it/s]\n",
      " 62%|██████▏   | 105048064/170498071 [00:07<00:03, 17861417.68it/s]\n",
      " 63%|██████▎   | 106882048/170498071 [00:07<00:03, 17501151.12it/s]\n",
      " 64%|██████▎   | 108662784/170498071 [00:07<00:03, 16056090.76it/s]\n",
      " 65%|██████▌   | 111232000/170498071 [00:07<00:03, 18357727.74it/s]\n",
      " 66%|██████▋   | 113125376/170498071 [00:07<00:03, 17720530.73it/s]\n",
      " 67%|██████▋   | 114936832/170498071 [00:07<00:03, 16539080.67it/s]\n",
      " 69%|██████▉   | 117286912/170498071 [00:07<00:02, 18354725.63it/s]\n",
      " 70%|██████▉   | 119174144/170498071 [00:07<00:02, 17735196.99it/s]\n",
      " 71%|███████   | 120984576/170498071 [00:08<00:03, 16481446.41it/s]\n",
      " 72%|███████▏  | 123094016/170498071 [00:08<00:02, 17694721.23it/s]\n",
      " 73%|███████▎  | 124905472/170498071 [00:08<00:02, 17652637.83it/s]\n",
      " 74%|███████▍  | 126700544/170498071 [00:08<00:02, 15928932.26it/s]\n",
      " 76%|███████▌  | 129156096/170498071 [00:08<00:02, 18167392.35it/s]\n",
      " 77%|███████▋  | 131035136/170498071 [00:08<00:02, 17529104.93it/s]\n",
      " 78%|███████▊  | 132832256/170498071 [00:08<00:02, 16333868.73it/s]\n",
      " 79%|███████▉  | 135300096/170498071 [00:08<00:01, 18462903.74it/s]\n",
      " 80%|████████  | 137201664/170498071 [00:09<00:01, 17928754.58it/s]\n",
      " 82%|████████▏ | 139032576/170498071 [00:09<00:01, 16133273.99it/s]\n",
      " 83%|████████▎ | 141362176/170498071 [00:09<00:01, 15868390.47it/s]\n",
      " 84%|████████▍ | 143721472/170498071 [00:09<00:01, 17734521.02it/s]\n",
      " 85%|████████▌ | 145563648/170498071 [00:09<00:01, 17513408.38it/s]\n",
      " 86%|████████▋ | 147360768/170498071 [00:09<00:01, 15918781.38it/s]\n",
      " 88%|████████▊ | 149996544/170498071 [00:09<00:01, 18576226.87it/s]\n",
      " 89%|████████▉ | 151934976/170498071 [00:09<00:01, 17800884.99it/s]\n",
      " 90%|█████████ | 153773056/170498071 [00:10<00:01, 16663787.31it/s]\n",
      " 92%|█████████▏| 156189696/170498071 [00:10<00:00, 18607091.48it/s]\n",
      " 93%|█████████▎| 158112768/170498071 [00:10<00:00, 17876897.96it/s]\n",
      " 94%|█████████▍| 159945728/170498071 [00:10<00:00, 16760304.65it/s]\n",
      " 95%|█████████▍| 161924096/170498071 [00:10<00:00, 17556651.86it/s]\n",
      " 96%|█████████▌| 163718144/170498071 [00:10<00:00, 17471641.58it/s]\n",
      " 97%|█████████▋| 165491712/170498071 [00:10<00:00, 16055613.08it/s]\n",
      " 98%|█████████▊| 167737344/170498071 [00:10<00:00, 17756338.86it/s]\n",
      "170499072it [00:10, 15578516.04it/s]                               \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(func pid=701)\u001b[0m Extracting ./data/cifar-10-python.tar.gz to ./data\n",
      "\u001b[2m\u001b[36m(func pid=701)\u001b[0m Files already downloaded and verified\n",
      "\u001b[2m\u001b[36m(func pid=701)\u001b[0m Files already downloaded and verified\n",
      "\u001b[2m\u001b[36m(func pid=701)\u001b[0m 18\n",
      "\u001b[2m\u001b[36m(func pid=701)\u001b[0m Config:  {'dp': 0.2, 'l2': 3.881646497434185e-05, 'ada_reg': 1.2875285396276522e-05, 'adv_weight': 0.7713116193859444, 'scale': 0.5391227821497242, 'lr': 0.005064982066547872}\n",
      "\u001b[2m\u001b[36m(func pid=701)\u001b[0m Epoch 0/14\n",
      "\u001b[2m\u001b[36m(func pid=701)\u001b[0m ----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(func pid=701)\u001b[0m E0308 13:18:59.167247433     729 fork_posix.cc:70]           Fork support is only compatible with the epoll1 and poll polling strategies\n",
      "\u001b[2m\u001b[36m(func pid=701)\u001b[0m E0308 13:18:59.197425859     729 fork_posix.cc:70]           Fork support is only compatible with the epoll1 and poll polling strategies\n",
      "\u001b[2m\u001b[36m(func pid=701)\u001b[0m E0308 13:27:07.345481251     729 fork_posix.cc:70]           Fork support is only compatible with the epoll1 and poll polling strategies\n",
      "\u001b[2m\u001b[36m(func pid=701)\u001b[0m E0308 13:27:07.371418639     729 fork_posix.cc:70]           Fork support is only compatible with the epoll1 and poll polling strategies\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(func pid=701)\u001b[0m Best loss:  1.5946197027206421\n",
      "\u001b[2m\u001b[36m(func pid=757)\u001b[0m Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/170498071 [00:00<?, ?it/s]\n",
      "  0%|          | 1024/170498071 [00:00<7:47:08, 6082.93it/s]\n",
      "  0%|          | 33792/170498071 [00:00<24:39, 115245.19it/s]\n",
      "  0%|          | 82944/170498071 [00:00<14:42, 193198.71it/s]\n",
      "  0%|          | 214016/170498071 [00:00<06:48, 416901.10it/s]\n",
      "  0%|          | 443392/170498071 [00:00<03:47, 746630.44it/s]\n",
      "  1%|          | 902144/170498071 [00:01<02:01, 1397321.25it/s]\n",
      "  1%|          | 1819648/170498071 [00:01<01:02, 2680450.49it/s]\n",
      "  2%|▏         | 3671040/170498071 [00:01<00:31, 5243928.89it/s]\n",
      "  4%|▎         | 6259712/170498071 [00:01<00:19, 8294537.84it/s]\n",
      "  5%|▌         | 8553472/170498071 [00:01<00:16, 9834450.54it/s]\n",
      "  7%|▋         | 11256832/170498071 [00:01<00:13, 11622428.75it/s]\n",
      "  8%|▊         | 13714432/170498071 [00:02<00:12, 12417168.08it/s]\n",
      " 10%|▉         | 16499712/170498071 [00:02<00:11, 13541212.99it/s]\n",
      " 11%|█         | 19006464/170498071 [00:02<00:10, 13842630.01it/s]\n",
      " 13%|█▎        | 21742592/170498071 [00:02<00:10, 14445478.48it/s]\n",
      " 14%|█▍        | 24331264/170498071 [00:02<00:10, 14610143.75it/s]\n",
      " 16%|█▌        | 27165696/170498071 [00:02<00:09, 15148585.56it/s]\n",
      " 17%|█▋        | 29754368/170498071 [00:03<00:09, 15094644.24it/s]\n",
      " 19%|█▉        | 32343040/170498071 [00:03<00:09, 15069664.62it/s]\n",
      " 21%|██        | 35341312/170498071 [00:03<00:08, 15764048.59it/s]\n",
      " 22%|██▏       | 38224896/170498071 [00:03<00:08, 16051038.18it/s]\n",
      " 24%|██▎       | 40371200/170498071 [00:03<00:08, 14966668.28it/s]\n",
      " 26%|██▌       | 43500544/170498071 [00:03<00:07, 15921761.94it/s]\n",
      " 27%|██▋       | 46269440/170498071 [00:04<00:07, 15921704.18it/s]\n",
      " 29%|██▉       | 49202176/170498071 [00:04<00:07, 16247147.33it/s]\n",
      " 31%|███       | 52102144/170498071 [00:04<00:07, 16410318.05it/s]\n",
      " 32%|███▏      | 55051264/170498071 [00:04<00:06, 16565341.54it/s]\n",
      " 34%|███▎      | 57197568/170498071 [00:04<00:07, 15328922.90it/s]\n",
      " 35%|███▌      | 60244992/170498071 [00:05<00:06, 16028031.39it/s]\n",
      " 37%|███▋      | 63341568/170498071 [00:05<00:06, 16601060.61it/s]\n",
      " 39%|███▊      | 65815552/170498071 [00:05<00:06, 15918728.63it/s]\n",
      " 40%|████      | 68813824/170498071 [00:05<00:06, 16355900.17it/s]\n",
      " 42%|████▏     | 71779328/170498071 [00:05<00:05, 16605424.15it/s]\n",
      " 43%|████▎     | 74056704/170498071 [00:05<00:06, 15586823.87it/s]\n",
      " 45%|████▌     | 77087744/170498071 [00:06<00:05, 16178123.99it/s]\n",
      " 47%|████▋     | 80086016/170498071 [00:06<00:05, 16538807.65it/s]\n",
      " 49%|████▊     | 83051520/170498071 [00:06<00:05, 16729247.27it/s]\n",
      " 50%|█████     | 85623808/170498071 [00:06<00:05, 16177571.30it/s]\n",
      " 52%|█████▏    | 88327168/170498071 [00:06<00:05, 16026059.63it/s]\n",
      " 54%|█████▎    | 91358208/170498071 [00:06<00:04, 16486037.00it/s]\n",
      " 55%|█████▌    | 94372864/170498071 [00:07<00:04, 16767874.24it/s]\n",
      " 57%|█████▋    | 97272832/170498071 [00:07<00:04, 16782100.43it/s]\n",
      " 59%|█████▊    | 100123648/170498071 [00:07<00:04, 16706706.40it/s]\n",
      " 60%|██████    | 102990848/170498071 [00:07<00:04, 16680070.09it/s]\n",
      " 62%|██████▏   | 105792512/170498071 [00:07<00:03, 16525438.91it/s]\n",
      " 64%|██████▍   | 108774400/170498071 [00:07<00:03, 16755859.75it/s]\n",
      " 66%|██████▌   | 111789056/170498071 [00:08<00:03, 16967285.35it/s]\n",
      " 67%|██████▋   | 114836480/170498071 [00:08<00:03, 17169809.36it/s]\n",
      " 69%|██████▉   | 117785600/170498071 [00:08<00:03, 17144140.09it/s]\n",
      " 71%|███████   | 120669184/170498071 [00:08<00:02, 16977839.02it/s]\n",
      " 73%|███████▎  | 123765760/170498071 [00:08<00:02, 17270763.26it/s]\n",
      " 74%|███████▍  | 126731264/170498071 [00:08<00:02, 17244940.51it/s]\n",
      " 76%|███████▌  | 129778688/170498071 [00:09<00:02, 17367125.70it/s]\n",
      " 78%|███████▊  | 132809728/170498071 [00:09<00:02, 17426844.69it/s]\n",
      " 80%|███████▉  | 135824384/170498071 [00:09<00:01, 17439005.14it/s]\n",
      " 81%|████████▏ | 138773504/170498071 [00:09<00:01, 17323399.87it/s]\n",
      " 83%|████████▎ | 141788160/170498071 [00:09<00:01, 17357090.43it/s]\n",
      " 85%|████████▍ | 144868352/170498071 [00:10<00:01, 17461285.65it/s]\n",
      " 87%|████████▋ | 147948544/170498071 [00:10<00:01, 17523047.50it/s]\n",
      " 89%|████████▊ | 151077888/170498071 [00:10<00:01, 17635141.19it/s]\n",
      " 90%|█████████ | 154108928/170498071 [00:10<00:00, 17603595.70it/s]\n",
      " 92%|█████████▏| 157156352/170498071 [00:10<00:00, 17571119.89it/s]\n",
      " 94%|█████████▍| 160050176/170498071 [00:10<00:00, 19819612.15it/s]\n",
      " 95%|█████████▌| 162148352/170498071 [00:10<00:00, 18104225.11it/s]\n",
      " 96%|█████████▌| 164038656/170498071 [00:11<00:00, 17483395.17it/s]\n",
      " 97%|█████████▋| 166020096/170498071 [00:11<00:00, 16052905.84it/s]\n",
      " 99%|█████████▉| 169133056/170498071 [00:11<00:00, 16674322.37it/s]\n",
      "170499072it [00:11, 14900486.61it/s]                               \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(func pid=757)\u001b[0m Extracting ./data/cifar-10-python.tar.gz to ./data\n",
      "\u001b[2m\u001b[36m(func pid=757)\u001b[0m Files already downloaded and verified\n",
      "\u001b[2m\u001b[36m(func pid=757)\u001b[0m Files already downloaded and verified\n",
      "\u001b[2m\u001b[36m(func pid=757)\u001b[0m 18\n",
      "\u001b[2m\u001b[36m(func pid=757)\u001b[0m Config:  {'dp': 0.1, 'l2': 0.0003291841312537266, 'ada_reg': 1.515965161568824e-05, 'adv_weight': 0.43427894511585396, 'scale': 0.42858641567824113, 'lr': 0.00036941252392986055}\n",
      "\u001b[2m\u001b[36m(func pid=757)\u001b[0m Epoch 0/14\n",
      "\u001b[2m\u001b[36m(func pid=757)\u001b[0m ----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(func pid=757)\u001b[0m E0308 13:27:49.631570020     785 fork_posix.cc:70]           Fork support is only compatible with the epoll1 and poll polling strategies\n",
      "\u001b[2m\u001b[36m(func pid=757)\u001b[0m E0308 13:27:49.665824955     785 fork_posix.cc:70]           Fork support is only compatible with the epoll1 and poll polling strategies\n",
      "\u001b[2m\u001b[36m(func pid=757)\u001b[0m E0308 13:35:52.892487232     785 fork_posix.cc:70]           Fork support is only compatible with the epoll1 and poll polling strategies\n",
      "\u001b[2m\u001b[36m(func pid=757)\u001b[0m E0308 13:35:52.920525165     785 fork_posix.cc:70]           Fork support is only compatible with the epoll1 and poll polling strategies\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(func pid=757)\u001b[0m Best loss:  1.321039206123352\n",
      "\u001b[2m\u001b[36m(func pid=757)\u001b[0m Epoch 1/14\n",
      "\u001b[2m\u001b[36m(func pid=757)\u001b[0m ----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(func pid=757)\u001b[0m E0308 13:36:08.500198098     785 fork_posix.cc:70]           Fork support is only compatible with the epoll1 and poll polling strategies\n",
      "\u001b[2m\u001b[36m(func pid=757)\u001b[0m E0308 13:36:08.526392451     785 fork_posix.cc:70]           Fork support is only compatible with the epoll1 and poll polling strategies\n",
      "\u001b[2m\u001b[36m(func pid=757)\u001b[0m E0308 13:44:13.132871875     785 fork_posix.cc:70]           Fork support is only compatible with the epoll1 and poll polling strategies\n",
      "\u001b[2m\u001b[36m(func pid=757)\u001b[0m E0308 13:44:13.163267656     785 fork_posix.cc:70]           Fork support is only compatible with the epoll1 and poll polling strategies\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(func pid=757)\u001b[0m Best loss:  1.222826982307434\n",
      "\u001b[2m\u001b[36m(func pid=757)\u001b[0m Epoch 2/14\n",
      "\u001b[2m\u001b[36m(func pid=757)\u001b[0m ----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(func pid=757)\u001b[0m E0308 13:44:28.751799099     785 fork_posix.cc:70]           Fork support is only compatible with the epoll1 and poll polling strategies\n",
      "\u001b[2m\u001b[36m(func pid=757)\u001b[0m E0308 13:44:28.783922054     785 fork_posix.cc:70]           Fork support is only compatible with the epoll1 and poll polling strategies\n",
      "\u001b[2m\u001b[36m(func pid=757)\u001b[0m E0308 13:52:32.285771529     785 fork_posix.cc:70]           Fork support is only compatible with the epoll1 and poll polling strategies\n",
      "\u001b[2m\u001b[36m(func pid=757)\u001b[0m E0308 13:52:32.312447723     785 fork_posix.cc:70]           Fork support is only compatible with the epoll1 and poll polling strategies\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(func pid=757)\u001b[0m Best loss:  1.1216665241241455\n",
      "\u001b[2m\u001b[36m(func pid=757)\u001b[0m Epoch 3/14\n",
      "\u001b[2m\u001b[36m(func pid=757)\u001b[0m ----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(func pid=757)\u001b[0m E0308 13:52:47.905639049     785 fork_posix.cc:70]           Fork support is only compatible with the epoll1 and poll polling strategies\n",
      "\u001b[2m\u001b[36m(func pid=757)\u001b[0m E0308 13:52:47.931556566     785 fork_posix.cc:70]           Fork support is only compatible with the epoll1 and poll polling strategies\n",
      "\u001b[2m\u001b[36m(func pid=757)\u001b[0m E0308 14:00:50.648202139     785 fork_posix.cc:70]           Fork support is only compatible with the epoll1 and poll polling strategies\n",
      "\u001b[2m\u001b[36m(func pid=757)\u001b[0m E0308 14:00:50.673751633     785 fork_posix.cc:70]           Fork support is only compatible with the epoll1 and poll polling strategies\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(func pid=757)\u001b[0m Best loss:  1.0370936120986938\n",
      "\u001b[2m\u001b[36m(func pid=757)\u001b[0m Epoch 4/14\n",
      "\u001b[2m\u001b[36m(func pid=757)\u001b[0m ----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(func pid=757)\u001b[0m E0308 14:01:06.174220559     785 fork_posix.cc:70]           Fork support is only compatible with the epoll1 and poll polling strategies\n",
      "\u001b[2m\u001b[36m(func pid=757)\u001b[0m E0308 14:01:06.203371350     785 fork_posix.cc:70]           Fork support is only compatible with the epoll1 and poll polling strategies\n",
      "\u001b[2m\u001b[36m(func pid=757)\u001b[0m E0308 14:09:07.014249444     785 fork_posix.cc:70]           Fork support is only compatible with the epoll1 and poll polling strategies\n",
      "\u001b[2m\u001b[36m(func pid=757)\u001b[0m E0308 14:09:07.039616833     785 fork_posix.cc:70]           Fork support is only compatible with the epoll1 and poll polling strategies\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(func pid=757)\u001b[0m Best loss:  1.0200728635787963\n",
      "\u001b[2m\u001b[36m(func pid=757)\u001b[0m Epoch 5/14\n",
      "\u001b[2m\u001b[36m(func pid=757)\u001b[0m ----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(func pid=757)\u001b[0m E0308 14:09:22.572624602     785 fork_posix.cc:70]           Fork support is only compatible with the epoll1 and poll polling strategies\n",
      "\u001b[2m\u001b[36m(func pid=757)\u001b[0m E0308 14:09:22.606160108     785 fork_posix.cc:70]           Fork support is only compatible with the epoll1 and poll polling strategies\n",
      "\u001b[2m\u001b[36m(func pid=757)\u001b[0m E0308 14:17:23.044836949     785 fork_posix.cc:70]           Fork support is only compatible with the epoll1 and poll polling strategies\n",
      "\u001b[2m\u001b[36m(func pid=757)\u001b[0m E0308 14:17:23.070174068     785 fork_posix.cc:70]           Fork support is only compatible with the epoll1 and poll polling strategies\n"
     ]
    }
   ],
   "source": [
    "from functools import partial\n",
    "\n",
    "config = {\n",
    "    \"dp\": tune.choice([0.5,0.4,0.3, 0.2,0.1]),\n",
    "    \"l2\": tune.loguniform(1e-5, 1e-2),\n",
    "    \"ada_reg\": tune.loguniform(1e-5, 1e-2),\n",
    "    \"adv_weight\": tune.uniform(0.4, 0.6),\n",
    "    \"scale\": tune.uniform(0.4, 0.6),\n",
    "    \"lr\": tune.loguniform(1e-4, 1e-2),\n",
    "}\n",
    "reporter = CLIReporter(\n",
    "    # parameter_columns=[\"l1\", \"l2\", \"lr\", \"batch_size\"],\n",
    "    metric_columns=[\"loss\", \"accuracy\",'training iteration'])\n",
    "\n",
    "scheduler = ASHAScheduler(\n",
    "        metric=\"loss\",\n",
    "        mode=\"min\",\n",
    "        max_t=20,\n",
    "        grace_period=1,\n",
    "        reduction_factor=2)\n",
    "\n",
    "result = tune.run(\n",
    "    partial(train_cifar),\n",
    "    resources_per_trial={\"cpu\": 2, \"gpu\": 1},\n",
    "    config=config,\n",
    "    num_samples=30,\n",
    "    verbose=0,\n",
    "    scheduler=scheduler,\n",
    "    progress_reporter=reporter,\n",
    ")\n",
    "\n",
    "best_trial = result.get_best_trial(\"loss\", \"min\", 'all')\n",
    "print(\"Best trial config: {}\".format(best_trial.config))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 23,
     "status": "ok",
     "timestamp": 1646707053917,
     "user": {
      "displayName": "SRP RESEARCH",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "13070729234973013197"
     },
     "user_tz": -60
    },
    "id": "TK-zko9E8ILk",
    "outputId": "67698c7b-4f2a-4643-a8e0-6873d6375dcc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best trial config: {'dp': 0.1, 'l2': 5.467130776888194e-06, 'ada_reg': 0.008446479631052932, 'adv_weight': 0.73428888168777, 'scale': 0.5988473674763856, 'lr': 0.004933134661531971}\n",
      "Best trial final validation loss: 0.9047795356750489\n",
      "Best trial final validation accuracy: 0.7273000000000001\n"
     ]
    }
   ],
   "source": [
    "best_trial = result.get_best_trial(\"loss\", \"min\", 'all')\n",
    "print(\"Best trial config: {}\".format(best_trial.config))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Hyperparameter tune (mlspgap).ipynb",
   "provenance": [
    {
     "file_id": "1L13VfVFzCSzN2-ficc6edkIM9TpHgTTK",
     "timestamp": 1646572205852
    },
    {
     "file_id": "1adtW-4JdTreVBCaVuGWKKjvm0MMF-lFq",
     "timestamp": 1637849961164
    },
    {
     "file_id": "1Kmy3vrA6KfHomj8AhxdtE63x4vDM7PER",
     "timestamp": 1637185153365
    },
    {
     "file_id": "1zP1K4_DmYwLdoVqOtRTl64_GErdpLw3j",
     "timestamp": 1637153450271
    },
    {
     "file_id": "1NO8yeCFEwvH5MJT8vTEitguzRodotv70",
     "timestamp": 1637080047977
    },
    {
     "file_id": "1KqsvcEwX_c2fNO1ds6o7MFo6hhlC0z9X",
     "timestamp": 1632243110103
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "07ca3b83b47f43dd82f49e0652de9627": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3d4d1725f2984182823214956c7a86db",
      "max": 170498071,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_2519d73fef1a428d88fdaa01032525e2",
      "value": 170498071
     }
    },
    "1de22a097bdd4ed18637e8ff9b5cd8ee": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_7baa3c40ce0b47449a2672e8fde1b39a",
       "IPY_MODEL_07ca3b83b47f43dd82f49e0652de9627",
       "IPY_MODEL_8e87dcaf35074494bd4607a41f50331a"
      ],
      "layout": "IPY_MODEL_26fd65390e934a8ab441a4fd6c53e275"
     }
    },
    "2519d73fef1a428d88fdaa01032525e2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "26fd65390e934a8ab441a4fd6c53e275": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3d4d1725f2984182823214956c7a86db": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5394197ac14946a29a8d7a32c394d780": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7baa3c40ce0b47449a2672e8fde1b39a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_acdebbc53d2a4b8a9730c83838b09b93",
      "placeholder": "​",
      "style": "IPY_MODEL_ac0705eefaa44dd5ba17ff4b3e727c1a",
      "value": ""
     }
    },
    "8e87dcaf35074494bd4607a41f50331a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5394197ac14946a29a8d7a32c394d780",
      "placeholder": "​",
      "style": "IPY_MODEL_bb17f1afd6994c1391d0271a2049fd3b",
      "value": " 170499072/? [00:12&lt;00:00, 15010374.87it/s]"
     }
    },
    "ac0705eefaa44dd5ba17ff4b3e727c1a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "acdebbc53d2a4b8a9730c83838b09b93": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "bb17f1afd6994c1391d0271a2049fd3b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
